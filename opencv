#一、Sobel滤波器：计算像素梯度
	1、sobel作用：索贝尔算子主要用作边缘检测。在技术上，它是一离散性差分算子，用来运算图像亮度函数的梯度之近似值。在图像的任何一点使用此算子，将会产生对应的梯度矢量或是其法矢量。
  
  2、如何计算梯度幅值和方向：
        Gx = [-1, 0, +1]
             [-2, 0, +2]
             [-1, 0, +1]

        Gy =  [-1, -2, -1]
              [0,   0,  0]
              [+1, +2, +1]
      梯度：G = (Gx **2 + Gy **2) ** 0.5
      方向：theta = arctan(Gy/Gx)
      
   3、缺点：对噪点具有平滑抑制作用，得到的边缘粗糙

   4、代码：
      laplacian = cv2.Laplacian(frame, cv2.CV_64F)
      sobelx = cv2.Sobel(frame, cv2.CV_64F, 1, 0, ksize=5)
      sobely = cv2.Sobel(frame, cv2.CV_64F, 0, 1, ksize=5)
      cv2.imshow("sobelx", sobelx)
      cv2.imshow("sobely", sobely)
      cv2.imshow("laplacian", laplacian)
      类似的算法：cv2.Scharr()

#二、图像金字塔：
	1、高斯金字塔：
        模糊（可用于图像拼接）
        API：
            cv2.pyrDown()\cv2.pyrUp()
  
  2、拉普拉斯锐化金字塔：
        用于找回原始丢掉的数据
  
  3、公式如下：
        Li = Gi -cv2.pyrDown(G(i+1))
        
#三、算法：
    1、canny算法：
        转灰度图
        高斯滤波
        计算图像梯度，根据梯度计算边缘幅值和角度
        非极大值抑制：用于瘦边，梯度垂直边缘，仅仅基于梯度值提取的便于那仍然很模糊，非极大值一直价则可以帮助将局部最大值之外的所有梯度值抑制为零
        （非极大值抑制：步骤
            将当前像素的梯度与沿正负梯度方向上的连个像素进行比较!
            如果当前像素强度与另外两个像素相比最大，则该像素点保留为边缘点，否则该像素点将被抑制）
        双阈值边缘链接处理
        二值化图像输出结果 
	2、增强对比度：
        cv2.convertScaleAbs()
     
#四、轮廓
##（一）、轮廓提取
	  1、转灰度图cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    2、转二值图cv2.threshold(imggray, 0, 255, cv2.THRESH_OSTU|cv2.THRESH_BINARY)
    
    3、提取轮廓cv2.findContours(binary, cv2.PETR_TREE, )
    
    4、刻画轮廓 cv2.drawContours(img, contours, 1, (0, 255, 0), 3)
    
    5、API：
      ①、参数：cv2.findContours(寻找轮廓的图像，
                检索模式：cv2.PETR_EXTERNAL只检测外轮廓、cv2.PETR_LIST检测的轮廓不建立等级关系、cv2.PETR_CCOMP建立两个等级的轮廓（上一层为外边界，里面一层为内轮廓的边界信息，如果内孔内还有一个连通物体，这个物体的边界也在顶层。    cv2.RETR_TREE建立一个等级树结构的轮廓）
                          轮廓近似办法：cv2.CHAIN_APPROX_SIMPLE存储所有的轮廓点，相邻的兰格点的像素位置不超过1（max（abs（x1-x2），abs（y2-y1））==1）、 cv2.CHAIN_APPROX_SIMPLE压缩水平方向，垂直方向，对角线方向的元素，只保留该方向的终点坐标，例如一个矩形轮廓只需4个点来保存轮廓信息)
      ②、返回值：一个是轮廓本身，其次是每条轮廓的的属性
    
    
    #计算面积、周长、中心位置
    #创建矩
    M = cv2.moments(contour[0])
    #矩阵重心
    cx, cy = int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"])
    #轮廓面积
    area = cv2.contourArea(contour[0])
    #轮廓周长
    length  =cv2.arcLength(contour[0], True)
##（二）、轮廓近似
	epsilon:大体轮廓距离实际轮廓的距离
	1、cv2.approxPolyDp(contours[0], epsilon, True)
    img1 = cv2.imread("6.jpg", 1)
i = 0
while video.isOpened():
    img = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    ret, img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU|cv2.THRESH_BINARY)
    
    #寻找轮廓点
    contour, tem = cv2.findContours(img, cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)
    
    #找到逼近轮廓的点的位置
    approx = cv2.approxPolyDP(contour[0], epsilon=30, closed=False)
    img_contour = cv2.drawContours(img1, [approx], -1, (255, 255, 0), 3)
    # print(approx)
    cv2.imshow("approx", img_contour)
    
    #判断是否是凸起
    hull = cv2.convexHull(contours[0])
    cv2.isContourConvex(contour[0], cv2.isContourvex(hull))
##（三）、边界检测
	
	1、边界矩形
    最小矩形
    最小外切圆
    最小椭圆
    
    #最小椭圆
    cntour, tem = cv2.findContour(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    imgellipse = cv2.fitEllipse(contour[0])
    cv2.ellipse(img1, imgellipse, color = (255, 0, 0),thickness=2)
    
    #最小直线
     h, w, _ = img1.shape
    [vx, vy, x, y] = cv2.fitLine(contour[0], cv2.DIST_L2,0,0.01, 0.01 )
    lefty = int((-x  * vy /vx) + y)
    rightly = int((w - x) * vy / vx+ y)
    cv2.line(img1, (w -1, rightly), (0, lefty), (255, 255, 0), 2)
    
    2、轮廓性质：
    ①边界矩形的宽高比
    Aspect Ratio = $$$Width/Height$$$
    x, y, w, h = cv2.boundingRect(cnt)
    aspect_ratio = float(w) / h
    
    ②轮廓面积与边界矩形面积的比
    Extent = Object Area/Bounding Rectangle Area
    area = cv2.contourArea(cont)
    x, y, w, h = cv2.boundingRect(cnt)
    rect_area = w*h
    extent = float(area) /rect_area
    
    3、轮廓匹配
    ①contour, hierarchy = cv2.findContours(binary, 2, 1)
	com_res = cv2.mathshapes(contour1[0], contour2[0], 1, 0.0)  #当两个图片完全相同时返回0，最大返回值为1
	②代码：
	    img1 = cv2.resize(img1, (400, 800))
    img2 = cv2.resize(img2, (400, 800))
    img1_ = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    img2_ = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

    contour1, _ = cv2.findContours(img1_, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    contour2, _ = cv2.findContours(img2_, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    result = cv2.matchShapes(contour1[0], contour2[0], 2, 0)
    result1 = cv2.matchShapes(img1_, img2_, 2, 0)
    print(result, result1)
    cv2.imshow("img1", img1_)
    cv2.imshow("img2", img2_)
	
    
##（一）、双边阈值处理
![da761330e99f07ea68f6b2003cf52fa.png](.\images\da761330e99f07ea68f6b2003cf52fa.png)

#六、Hough变换
	1、作用：用来检测任意能够用数学公式表达的形状（现实情况中曲线不一定由公式而来
	2、代码：
	#获取圆的属性：中心点坐标，直径
	circles = cv2.HoughCircles(dst, cv2.HOUGH_GRADIENT, dp=1, minDist=30, param1=40, param2=20, minRadius=20, maxRadius=300)
	#获取直线属性：交点坐标和角度
	lines = cv2.HoughLines(edges, 1, np.pi/180, 100)
	！[](![120991f1f17a93b28f779feaf28e8dd.png](.\images\120991f1f17a93b28f779feaf28e8dd.png)
  ![9260544fb06b96bf8824460682ecdd3.png](.\images\9260544fb06b96bf8824460682ecdd3.png)

#七、直方图
1、2D直方图（待补充）：
	一般使用HSV格式，cv2.COLOR_BGR2HSV

#八、分水岭算法
	1、图像距离转换，距离边缘cv2.distanceTransform()	
	距离转换图像，其中dst每个像素的值为其到最近的背景像素（灰度值为0）的距离，可以看到硬币的中心像素值最大（中心离背景像素最远）。对其进行二值处理就得到了分离的前景图（下面中间的图），白色区域肯定是硬币区域，而且还相互分离，下面右边的图为之前的膨胀图减去中间这个表示前景的图。


#九、欧拉放大
  import cv2
  import numpy as np
  import scipy.fftpack as fftpack

  #####---------------------------------欧拉放大
  ###### Build Gaussian Pyramid
  def build_gaussian_pyramid(src, level=3):
      s = src.copy()
      pyramid = [s]
      for i in range(level):
          s = cv2.pyrDown(s)
          pyramid.append(s)
      return pyramid


###### load video from file
def load_video(video_filename):
    #捕获视频
    cap = cv2.VideoCapture(video_filename)
    #？？？？？？？？？
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    #帧、宽、高
    video_tensor = np.zeros((frame_count, height, width, 3), dtype='float')
    x = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if ret is True:
            video_tensor[x] = frame
            x += 1
        else:
            break
    return video_tensor, fps


###### apply temporal ideal bandpass filter to gaussian video
def temporal_ideal_filter(tensor, low, high, fps, axis=0):
    #傅里叶变换，谐波分解分析，tensor维度（帧、宽、高、通道）
    fft = fftpack.fft(tensor, axis=axis)
    #将图像平移，逆变换时区间对称(-inf,+inf)
    frequencies = fftpack.fftfreq(tensor.shape[0], d=1.0 / fps)
    bound_low = (np.abs(frequencies - low)).argmin()
    bound_high = (np.abs(frequencies - high)).argmin()
    fft[:bound_low] = 0
    fft[bound_high:-bound_high] = 0
    fft[-bound_low:] = 0
    iff = fftpack.ifft(fft, axis=axis)
    return np.abs(iff)


###### build gaussian pyramid for video
def gaussian_video(video_tensor, levels=3):
    for i in range(0, video_tensor.shape[0]):
        frame = video_tensor[i]
        pyr = build_gaussian_pyramid(frame, level=levels)
        gaussian_frame = pyr[-1]
        if i == 0:
            vid_data = np.zeros((video_tensor.shape[0], gaussian_frame.shape[0], gaussian_frame.shape[1], 3))
        vid_data[i] = gaussian_frame
    return vid_data


###### amplify the video
def amplify_video(gaussian_vid, amplification=50):
    return gaussian_vid * amplification

###### reconstract video from original video and gaussian video
def reconstract_video(amp_video, origin_video, levels=3):
    final_video = np.zeros(origin_video.shape)
    for i in range(0, amp_video.shape[0]):
        img = amp_video[i]
        for x in range(levels):
            img = cv2.pyrUp(img)
        img = img + origin_video[i]
        final_video[i] = img
    return final_video

#######save video to files
def save_video(video_tensor):
    fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')
    [height, width] = video_tensor[0].shape[0:2]
    writer = cv2.VideoWriter("out.avi", fourcc, 30, (width, height), 1)
    for i in range(0, video_tensor.shape[0]):
        writer.write(cv2.convertScaleAbs(video_tensor[i]))
    writer.release()


###### magnify color

def magnify_color(video_name, low, high, levels=3, amplification=20):
    #载入图片
    t, f = load_video(video_name)
    gau_video = gaussian_video(t, levels=levels)
    #中通滤波
    filtered_tensor = temporal_ideal_filter(gau_video, low, high, f)
    #放大
    amplified_video = amplify_video(filtered_tensor, amplification=amplification)
    #重构
    final = reconstract_video(amplified_video, t, levels=3)
    save_video(final)

if __name__ == "__main__":
    magnify_color("baby.mp4", 0.4, 3)


#十、特征提取
#####（一）、特征提取
1、Harris角点提取
	代码：
	import cv2
	import numpy as np
	video = cv2.VideoCapture(0)
	kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3 ))
	while video.isOpened():
		ret, frame = video.read()
		img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
		img = np.float32(img)
		dst = cv2.cornerHarris(img, 2, 3, 0.04)
		frame[dst > (0.01 * dst.max())] = [0, 0, 255]

		frame = cv2.dilate(frame, kernel)
		cv2.imshow("frame", frame)
		cv2.waitKey(50)
2、SIFT（待补充）


3、FAST算法（待补充）

4、BRIF（binary robust independ Elementart features)
[1, 0, 0, 1]
[1, 1, 0, 0]
相同记1，不同记0
海明距离：2

#####（二）、特征匹配
######Brute-Force蛮力匹配
查询图->被查询图（使用汉明（海明）距离）
img1 = cv2.imread("1.jpg", 1)
img2 = cv2.imread("2.jpg", 1)
orb = cv2.ORB_create()
kp1, des1 = orb.detectAndCompute(img1, None)
kp2, des2 = orb.detectAndCompute(img2, None)
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True #pe
matches = bf.match(des1, des2) #匹配
matches = sorted(matches, key = lambda x:x.distance)#排序，每一个特征都是一个向量，将向量与向量进行对比，选择距离最近的10个向量
img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:10], None)
cv2.imshow("img3", img3)

#十一、跟踪算法（自行研究）

#last
1、sobel、rewitt、拉普拉斯算子之间的区别：
https://blog.csdn.net/Chaolei3/article/details/79809703

2、canny算法参考：
https://baike.baidu.com/item/canny%E7%AE%97%E6%B3%95/8439208
